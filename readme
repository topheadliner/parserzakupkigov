Программа парсит карточки-сделки с сайта госзакупок. Парсит ссылку на каждую карточку. Для того, чтобы парсить другие
элементы, идем вниз по дереву и дописываем атрибуты через функцию .find, например для номера карточки берем код
элемента - <div class="registry-entry__header-mid__number">, для парсинга начальной цены ее код элемента -
<div class="price-block__value">872 432,50 ₽</div>.


Сначала! Обязательно в CMD инсталлим нужные пакеты:
pip install requests, beautifulsoup4, lxml - три библиотеки, еще плюс pandas


for p in range(1, 5):   # понятно, что парсим 4 первые страницы

r = requests.get(url)   #после отправляем запрос непосредственно на сервер с помощью команды get, на вход которой переменную url
r.text  #чтобы вернуть наш код в виде текста, эту строку можем скипнуть
soup = bs(r.text, 'lxml') #ответ передаем библиотеке, указывая интересующий формат - lxml
#далее юзаем функцию find, указав тег и класс нужного элемента

# то что пишем в shell если без переменной, или присваиваем переменную каждому запросу, и вызываем в shell по переменной
card = soup.find('div', class_="registry-entry__header-mid__number")   # так мы получили элемент, обратившись к нему по тегу
card_link = soup.find('div', class_="registry-entry__header-mid__number").find('a').get('href')     # получили ссылку элемента, спустившись глубже по дереву
cards = soup.findAll('div', class_="registry-entry__header-mid__number")    # все варианты с таким тегом, т.е. все карточки

# делаем цикл обхода по каждой карточке с госзакупок
for card in cards:
    link = card.find('a').get('href')
    print(link)
